\documentclass{beamer}
\usetheme{metropolis}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\newenvironment{bigitemize}{\itemize\addtolength{\itemsep}{10pt}}{\enditemize}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\title{Microeconometrics Module}
\subtitle{Lecture 2: Miscellaneous Concepts}
\author{Swapnil Singh}
\date{Lietuvos Bankas and KTU \\ \href{https://github.com/swapnil1987/econometrics-2024}{\textcolor{magenta}{Course Link}}}

\begin{document}
	
	\maketitle


\begin{frame}
	\frametitle{Introduction}
	
	\begin{itemize}
		\item Clarification of some concepts
			\begin{enumerate}
				\item Definition of \emph{estimand, estimate,} and {estimator}
				\item Different causal estimands
				\item Understanding identification
			\end{enumerate}
	\end{itemize}
\end{frame}

\begin{frame}{Estimand, Estimate, and Estimator}
	\begin{itemize}
		\item \textbf{Estimand}: A parameter or a function of the population that we aim to measure. 
			\begin{itemize} 
				\item  \textit{True value} that we are interested in knowing 
				\item Example: The average income of all households in a country.
			\end{itemize}
		
		\item \textbf{Estimator}: A rule or a formula that tells us how to calculate  estimand based on sample data. 
		
		\item \textbf{Estimate}: The actual value obtained by applying the estimator to a given set of sample data. 
		\begin{itemize}
			\item Example: The calculated value of \$50,000 as the average income from the sample data.
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{}
	\begin{center}
		\Large\textcolor{blue}{Causal Estimands}
	\end{center}
\end{frame}


\begin{frame}
	\frametitle{Different Causal Estimands}
	\begin{itemize}
		\item Three types of estimands are interesting for us:
			\begin{enumerate}
				\item Average treatment effect i.e. $\tau_{ATE}$
				\item Average treatment effect on the treated i.e. $\tau_{ATET}$
				\item Conditional average treatment effect i.e. $\tau_{CATE}$
			\end{enumerate}
		\item \textbf{Average treatment effect  } i.e. $\tau_{ATE}$
			\begin{align*}
				\tau_{ATE} &= \mathbb E(\tau_i)\\
				&= \mathbb E[ Y_{i}(1) - Y_i(0) ]
			\end{align*}
		where $\mathbb E(\boldsymbol{\cdot})$ is the population operator 
		\item Note that until now we are not talking about the type of data we have
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Different Causal Estimands}
	\begin{itemize}
		\item \textbf{Average treatment effect on the treated} i.e. $\tau_{ATET}$
			\begin{align*}
				\tau_{ATET} &= \mathbb E(\tau_i | D_i = 1) \\
				&= \mathbb E[Y_i(1) - Y_i(0) | D_i=1]\\
				&= \underbrace{\mathbb E[Y_i(1)  | D_i=1]}_{observed} - \mathbb E[ Y_i(0) | D_i=1]
			\end{align*}
	\end{itemize}
\end{frame}



\begin{frame}
	\frametitle{Different Causal Estimands}
	\begin{itemize}
		\item \textbf{Conditional average treatment effect} i.e. $\tau_{CATE}$
		\begin{align*}
			\tau_{CATE}(x) &= \mathbb E(\tau_i | X_i = x) \\
			&= \mathbb E[Y_i(1) - Y_i(0) | X_i=x]
		\end{align*}
	where $X_i$ is some observed characteristic
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{}
	\begin{center}
		\Large\textcolor{blue}{Understanding Identification}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Types of identification}
	\begin{itemize}
		\item Two types of identification\footnote{Lewbel, A. (2019). The Identification Zoo: Meanings of Identification in Econometrics. Journal of Economic Literature, 57 (4): 835-903.
		}:
			\begin{enumerate}
				\item Point identification, or as Prof. Beatrice Cherrier calls in her \hyperlink{https://twitter.com/jondr44/status/1763348001668387071}{\beamerbutton{X/Twitter post}} Ashenfelter-Angrist-Lalonde-Card-Krueger approach
				\item Partial identification, see Tamer (2010)\footnote{Tamer, E. (2010). Partial identification in econometrics. Annu. Rev. Econ., 2(1), 167-195.}
			\end{enumerate}
		\item This module: point identification
		
		\item But, let's first dig into understanding the meaning of identification
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Understanding identification}
	\begin{columns}[T] % align columns
		\begin{column}{0.7\linewidth}
			\begin{bigitemize}
				\item Let $\theta$ denote an unknown parameter or a \textit{set} of unknown parameters
				\item Our objective is to learn/estimate $\theta$
			\end{bigitemize}	
		\end{column}
		%
		\pause
		\begin{column}{0.25\linewidth}
			\textbf{Ex:} In linear regression models, i.e. $y = \alpha + \beta x + \epsilon$, $\theta$ can be $\alpha, \beta$\\
			\pause
			\textbf{Ex:} $\tau_{ATE}$
		\end{column}
	\end{columns}

	\begin{itemize}
		\item Identification means, if we knew the population the data is drawn from, can we infer information about $\theta$
		\item Another way to think: 
			\begin{itemize}
				\item variation in $\theta$ $\implies$ variation in the distribution of data
			\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Point identification}
	\begin{columns}[T]
		\begin{column}{0.6\linewidth}
			\begin{itemize}
				\item We want to identify and estimate $\theta$
				\item Assume, there exists $\phi$
				\begin{itemize}
					\item $\phi$ can be learned from the data
				\end{itemize}
			\end{itemize}	
		\end{column}
		%
		\pause
		\begin{column}{0.3\linewidth}
			Ex. of $\phi$: distribution function, conditional means, quantiles, etc.
		\end{column}
	\end{columns}
	\vspace{1cm}
	\pause
	\begin{itemize}
		\item Essentially, we will leverage $\phi$ to get to know $\theta$
		\item To bridge this knowledge, we need a model
		\item Model puts restriction on what values $\phi$ can take
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Point Identification: Example 1}
	\begin{itemize}
		\item Suppose there are two variables $y$ and $x$
		\item Our model is that there is a \textbf{linear} relationship between $y$ and $x$, i.e.
			\begin{align*}
				y = x\theta + \varepsilon, \;\;\; \mathbb E(x^2) \neq 0, \;\;\; \mathbb E[ex] = 0
			\end{align*}
		\item Let's say we can learn second moments of $(y,x)$ i.e. we know what $\phi$ is
		\item Then, we know 
			\begin{align*}
				\theta = \frac{\mathbb E(xy)}{\mathbb E(x^2)}
			\end{align*}
		\item $\theta$ is point identified
		\item However, if we were not able to calculate second moments, then $\theta$ is not point identified
	\end{itemize}
\end{frame}





\begin{frame}
	\frametitle{}
	
	\begin{center}
		\Large\textcolor{blue}{Identification of treatment effect}
	\end{center}
\end{frame}

\begin{frame}
	\frametitle{Strong Ignorability}
	
	\begin{definition}
		$D_i$ is strongly ignorable conditional on $\boldsymbol{X}_i$ if 
		
		\begin{enumerate}
			\item Potential outcomes are independent of treatment, conditional on $X_i$ i.e.
				\begin{align*}
					Y_i(1),  Y_i(0) \independent D_i | X_i
				\end{align*}
			\item The treatment is not too rare or common, i.e.
				\begin{align*}
					\exists \epsilon > 0, \;\text{s.t.} \; \epsilon < Pr(D_i = 1 | X_i) < 1 - \epsilon
				\end{align*}
		\end{enumerate}
	\end{definition}
\end{frame}


\begin{frame}
	\frametitle{ATE Point Identification}
	\begin{theorem}
		If $D_i$ is strongly ignorable conditional on $X_i$, then 
		
		\begin{align*}
			ATE &= \mathbb E(\tau_i) \\
			&= \int_{x \in \Omega(X_i)} \left[\mathbb E(Y_i | D_i=1, X_i=x) - \mathbb E(Y_i | D_i=0, X_i=x)\right] f(x) dx
		\end{align*}
	\end{theorem}
\end{frame}


\begin{frame}
	\frametitle{Next}
	\begin{itemize}
		\item Endogeneity
	\end{itemize}
\begin{center}
	\Large\textcolor{blue}{Questions?}
\end{center}
\end{frame}



\end{document}